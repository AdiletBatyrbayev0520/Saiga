{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d52ee59e",
   "metadata": {},
   "source": [
    "## 0. Importing all necessary libs and tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65e58bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_4 512 slices predicted_images_with_annotations 0.4 iou_filtered outlier_filtered 3 0.5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "for module_name in list(sys.modules.keys()):\n",
    "    if module_name.startswith('src.'):\n",
    "        del sys.modules[module_name]\n",
    "from src.config import MODEL_NAME, OVERLAPPING_PERCENTAGE, SLICE_SIZE, SLICES_FOLDER, PREDICT_FOLDER_PREFIX, CONFIDENCE_THRESHOLD, IOU_FOLDER_PREFIX, OUTLIER_FILTER_FOLDER_PREFIX, OUTLIER_THRESHOLD_K, IOU_THRESHOLD\n",
    "print(MODEL_NAME, SLICE_SIZE, SLICES_FOLDER, PREDICT_FOLDER_PREFIX, CONFIDENCE_THRESHOLD, IOU_FOLDER_PREFIX, OUTLIER_FILTER_FOLDER_PREFIX, OUTLIER_THRESHOLD_K, IOU_THRESHOLD)\n",
    "from src.model import get_devices, get_models, process_images, read_annotation_file, create_annotation_file\n",
    "from src.tools.utils import get_destination_folder, create_destination_folder, get_slice_coordinates\n",
    "from src.tools.image_slicer import create_image_slices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b3162",
   "metadata": {},
   "source": [
    "## 1. Slicing image process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b7c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = \"dataset/0.0.1/АФС для обработки ИИ\"\n",
    "image_paths = [f\"{images_folder}/{image_path}\" for image_path in os.listdir(images_folder)]\n",
    "for image_path in image_paths:\n",
    "    create_image_slices(\n",
    "        image_path=image_path, \n",
    "        overlap_percentage=OVERLAPPING_PERCENTAGE, \n",
    "        destination_folder=SLICES_FOLDER,\n",
    "        slice_size=SLICE_SIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9baac8",
   "metadata": {},
   "source": [
    "## 1.2 Parallel slicing approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453e5761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 211 images using 3 processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/211 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from src.tools.image_slicer import create_image_slices_parallel\n",
    "create_image_slices_parallel(OVERLAPPING_PERCENTAGE, SLICES_FOLDER, SLICE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef840f",
   "metadata": {},
   "source": [
    "## 2. Processing slices with yolo model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d906d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = get_devices()\n",
    "models = get_models(MODEL_NAME, devices)\n",
    "folder_name = get_destination_folder([PREDICT_FOLDER_PREFIX, MODEL_NAME, CONFIDENCE_THRESHOLD])\n",
    "output_folder = create_destination_folder(folder_name)\n",
    "boxes_list = process_images(models[0], output_folder, devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27813b30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saiga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
