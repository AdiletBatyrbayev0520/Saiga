{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d52ee59e",
   "metadata": {},
   "source": [
    "## 0. Importing all necessary libs and tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e58bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_4 640 slices predicted_images_with_annotations 0.4 iou_filtered outlier_filtered 3 0.5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "for module_name in list(sys.modules.keys()):\n",
    "    if module_name.startswith('src.'):\n",
    "        del sys.modules[module_name]\n",
    "from src.config import MODEL_NAME, OVERLAPPING_PERCENTAGE, SLICE_SIZE, SLICES_FOLDER, PREDICT_FOLDER_PREFIX, CONFIDENCE_THRESHOLD, IOU_FOLDER_PREFIX, OUTLIER_FILTER_FOLDER_PREFIX, OUTLIER_THRESHOLD_K, IOU_THRESHOLD\n",
    "print(MODEL_NAME, SLICE_SIZE, SLICES_FOLDER, PREDICT_FOLDER_PREFIX, CONFIDENCE_THRESHOLD, IOU_FOLDER_PREFIX, OUTLIER_FILTER_FOLDER_PREFIX, OUTLIER_THRESHOLD_K, IOU_THRESHOLD)\n",
    "from src.model import get_devices, get_models, process_folder, read_annotation_file, create_annotation_file, process_folders_parallel\n",
    "from src.tools.utils import get_destination_folder, create_destination_folder, get_slice_coordinates\n",
    "from src.tools.image_slicer import create_image_slices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b3162",
   "metadata": {},
   "source": [
    "## 1. Slicing image process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b7c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = \"dataset/0.0.1/АФС для обработки ИИ\"\n",
    "image_paths = [f\"{images_folder}/{image_path}\" for image_path in os.listdir(images_folder)]\n",
    "for image_path in image_paths:\n",
    "    create_image_slices(\n",
    "        image_path=image_path, \n",
    "        overlap_percentage=OVERLAPPING_PERCENTAGE, \n",
    "        destination_folder=SLICES_FOLDER,\n",
    "        slice_size=SLICE_SIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9baac8",
   "metadata": {},
   "source": [
    "## 1.2 Parallel slicing approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453e5761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 211 images using 20 processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 211/211 [00:59<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed: 211 images, 37136 total slices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.tools.image_slicer import create_images_slices_parallel\n",
    "create_images_slices_parallel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef840f",
   "metadata": {},
   "source": [
    "## 2. Processing slices with yolo model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d906d4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA доступна: True\n",
      "Название GPU: NVIDIA GeForce RTX 5090\n",
      "Количество GPU: 2\n",
      "Текущий GPU device: 0\n",
      "Доступные устройства: ['cuda:0', 'cuda:1']\n",
      "Модель загружена на: cuda:0\n",
      "Модель загружена на: cuda:1\n",
      "Using devices: ['cuda:0', 'cuda:1']\n",
      "Обработка изображений на устройстве: cuda:1\n",
      "пПапка вывода: predicted_images_with_annotations-best_4-0.4-2\n",
      "Обработано: 10 изображений с детекциями\n",
      "Обработано: 20 изображений с детекциями\n",
      "Обработано: 30 изображений с детекциями\n",
      "Обработано: 40 изображений с детекциями\n",
      "Обработано: 50 изображений с детекциями\n",
      "Обработано: 60 изображений с детекциями\n",
      "Обработано: 70 изображений с детекциями\n",
      "Обработано: 80 изображений с детекциями\n",
      "Обработано: 90 изображений с детекциями\n",
      "Обработано: 100 изображений с детекциями\n",
      "Обработано: 110 изображений с детекциями\n",
      "Обработано: 120 изображений с детекциями\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m folder_name = get_destination_folder([PREDICT_FOLDER_PREFIX, MODEL_NAME, CONFIDENCE_THRESHOLD, \u001b[33m\"\u001b[39m\u001b[33m2\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      5\u001b[39m output_folder = create_destination_folder(folder_name)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m boxes_list = \u001b[43mprocess_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sduai\\Desktop\\Batyrbayev_Adilet\\qCloudy\\Projects\\PoC\\Saiga\\src\\model.py:138\u001b[39m, in \u001b[36mprocess_images\u001b[39m\u001b[34m(model, device, output_folder)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m os.listdir(folder_path):\n\u001b[32m    137\u001b[39m     full_image_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     predictions = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIDENCE_THRESHOLD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(predictions[\u001b[32m0\u001b[39m].boxes.conf) > \u001b[32m0\u001b[39m:\n\u001b[32m    141\u001b[39m         boxes_data = {\u001b[33m'\u001b[39m\u001b[33msource_image_path\u001b[39m\u001b[33m'\u001b[39m: full_image_path, \u001b[33m'\u001b[39m\u001b[33mcoordinates\u001b[39m\u001b[33m'\u001b[39m: predictions[\u001b[32m0\u001b[39m].boxes.xyxy.tolist()}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sduai\\Desktop\\Batyrbayev_Adilet\\qCloudy\\Projects\\PoC\\Saiga\\.venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:557\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, source, stream, predictor, **kwargs)\u001b[39m\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.predictor, \u001b[33m\"\u001b[39m\u001b[33mset_prompts\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[32m    556\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor.set_prompts(prompts)\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor.predict_cli(source=source) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sduai\\Desktop\\Batyrbayev_Adilet\\qCloudy\\Projects\\PoC\\Saiga\\.venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:229\u001b[39m, in \u001b[36mBasePredictor.__call__\u001b[39m\u001b[34m(self, source, model, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_inference(source, model, *args, **kwargs)\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sduai\\Desktop\\Batyrbayev_Adilet\\qCloudy\\Projects\\PoC\\Saiga\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:38\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     41\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     42\u001b[39m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sduai\\Desktop\\Batyrbayev_Adilet\\qCloudy\\Projects\\PoC\\Saiga\\.venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:326\u001b[39m, in \u001b[36mBasePredictor.stream_inference\u001b[39m\u001b[34m(self, source, model, *args, **kwargs)\u001b[39m\n\u001b[32m    320\u001b[39m profilers = (\n\u001b[32m    321\u001b[39m     ops.Profile(device=\u001b[38;5;28mself\u001b[39m.device),\n\u001b[32m    322\u001b[39m     ops.Profile(device=\u001b[38;5;28mself\u001b[39m.device),\n\u001b[32m    323\u001b[39m     ops.Profile(device=\u001b[38;5;28mself\u001b[39m.device),\n\u001b[32m    324\u001b[39m )\n\u001b[32m    325\u001b[39m \u001b[38;5;28mself\u001b[39m.run_callbacks(\u001b[33m\"\u001b[39m\u001b[33mon_predict_start\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mon_predict_batch_start\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim0s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sduai\\Desktop\\Batyrbayev_Adilet\\qCloudy\\Projects\\PoC\\Saiga\\.venv\\Lib\\site-packages\\ultralytics\\data\\loaders.py:465\u001b[39m, in \u001b[36mLoadImagesAndVideos.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    463\u001b[39m         im0 = cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)  \u001b[38;5;66;03m# convert image to BGR nparray\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     im0 = \u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv2_flag\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# BGR\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m im0 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    467\u001b[39m     LOGGER.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mImage Read Error \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sduai\\Desktop\\Batyrbayev_Adilet\\qCloudy\\Projects\\PoC\\Saiga\\.venv\\Lib\\site-packages\\ultralytics\\utils\\patches.py:43\u001b[39m, in \u001b[36mimread\u001b[39m\u001b[34m(filename, flags)\u001b[39m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     im = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m im[..., \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;28;01mif\u001b[39;00m im \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m im.ndim == \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m im\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "devices = get_devices()\n",
    "models = get_models(MODEL_NAME, devices)\n",
    "print(f\"Using devices: {devices}\")\n",
    "folder_name = get_destination_folder([PREDICT_FOLDER_PREFIX, MODEL_NAME, CONFIDENCE_THRESHOLD, \"2\"])\n",
    "output_folder = create_destination_folder(folder_name)\n",
    "boxes_list = process_folders(models[1], devices[1], output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2828399",
   "metadata": {},
   "source": [
    "## 2.2 Processing folders parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27813b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA доступна: True\n",
      "Название GPU: NVIDIA GeForce RTX 5090\n",
      "Количество GPU: 2\n",
      "Текущий GPU device: 0\n",
      "Доступные устройства: ['cuda:0', 'cuda:1']\n",
      "Модель загружена на: cuda:0\n",
      "Модель загружена на: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folders:   0%|          | 0/211 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "devices = get_devices()\n",
    "models = get_models(MODEL_NAME, devices)\n",
    "folder_name = get_destination_folder([PREDICT_FOLDER_PREFIX, MODEL_NAME, CONFIDENCE_THRESHOLD, \"2\"])\n",
    "output_folder = create_destination_folder(folder_name)\n",
    "total_detections = process_folders_parallel(models, devices, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e76041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saiga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
