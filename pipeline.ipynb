{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c660f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.tools.image_slicer import create_image_slices\n",
    "images_folder = \"dataset/0.0.1/АФС для обработки ИИ\"\n",
    "image_paths = [f\"{images_folder}/{image_path}\" for image_path in os.listdir(images_folder)]\n",
    "for image_path in image_paths:\n",
    "    create_image_slices(\n",
    "        image_path=image_path, \n",
    "        overlap_percentage=10, \n",
    "        destination_folder=\"slices\",\n",
    "        slice_size=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b12afc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_4 640 slices predicted_images_with_annotations 0.4 iou_filtered outlier_filtered 3 0.5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "for module_name in list(sys.modules.keys()):\n",
    "    if module_name.startswith('src.'):\n",
    "        del sys.modules[module_name]\n",
    "from main.resources.config import MODEL_NAME, OVERLAPPING_PERCENTAGE, SLICE_SIZE, SLICES_FOLDER, PREDICT_FOLDER_PREFIX, CONFIDENCE_THRESHOLD, IOU_FOLDER_PREFIX, OUTLIER_FILTER_FOLDER_PREFIX, OUTLIER_THRESHOLD_K, IOU_THRESHOLD\n",
    "print(MODEL_NAME, SLICE_SIZE, SLICES_FOLDER, PREDICT_FOLDER_PREFIX, CONFIDENCE_THRESHOLD, IOU_FOLDER_PREFIX, OUTLIER_FILTER_FOLDER_PREFIX, OUTLIER_THRESHOLD_K, IOU_THRESHOLD)\n",
    "from main.python.tools.model import get_devices, get_models, process_folders, process_folder, read_annotation_file, create_annotation_file\n",
    "from src.tools.utils import get_destination_folder, create_destination_folder, get_slice_coordinates\n",
    "from src.tools.image_slicer import create_image_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52ec62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_devices():\n",
    "    devices = []\n",
    "    print(f\"CUDA доступна: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Название GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"Количество GPU: {torch.cuda.device_count()}\")\n",
    "        print(f\"Текущий GPU device: {torch.cuda.current_device()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            devices.append(f'cuda:{i}')\n",
    "        print(f\"Доступные устройства: {devices}\")\n",
    "    else:\n",
    "        print(\"CUDA недоступна, используется CPU\")\n",
    "        devices.append('cpu')\n",
    "    return devices\n",
    "\n",
    "def get_models(model_name, devices):\n",
    "    models = []\n",
    "    for device in devices:\n",
    "        models.append(YOLO(f'{model_name}.pt'))\n",
    "        models[-1].to(device)\n",
    "        print(f\"Модель загружена на: {device}\")\n",
    "    return models\n",
    "\n",
    "def get_destination_folder(output_folder_prefix, model_name, confidence_threshold):\n",
    "    return f\"{output_folder_prefix}-{model_name}-{confidence_threshold}\"\n",
    "\n",
    "def create_destination_folder(output_folder_prefix, model_name, confidence_threshold):\n",
    "    output_folder = get_destination_folder(output_folder_prefix, model_name, confidence_threshold)\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    return output_folder\n",
    "\n",
    "def copyfile(source_path, destination_path):\n",
    "    if not os.path.exists(destination_path):\n",
    "        os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n",
    "    with open(source_path, 'rb') as src, open(destination_path, 'wb') as dst:\n",
    "        dst.write(src.read())\n",
    "        \n",
    "def copyfolder(source_folder, destination_folder):\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder, exist_ok=True)\n",
    "    for item in os.listdir(source_folder):\n",
    "        source_path = os.path.join(source_folder, item)\n",
    "        destination_path = os.path.join(destination_folder, item)\n",
    "        if os.path.isdir(source_path):\n",
    "            copyfolder(source_path, destination_path)\n",
    "        else:\n",
    "            copyfile(source_path, destination_path)\n",
    "\n",
    "def create_classes_file(output_folder):\n",
    "    with open(f\"{output_folder}/classes.txt\", \"w\") as f:\n",
    "        f.write(\"saiga\\n\")\n",
    "\n",
    "def create_annotation_file(image_path, boxes, output_folder, image_size=512):\n",
    "    if not os.path.exists(f\"{output_folder}/classes.txt\"):\n",
    "        create_classes_file(output_folder)\n",
    "    \n",
    "    filename = image_path.split('/')[-1].split('.')[0]\n",
    "    with open(f\"{output_folder}/{filename}.txt\", \"w\") as f:  # \"w\" вместо \"a\"\n",
    "        for box in boxes:\n",
    "            x_center = (box[0] + box[2]) / 2 / image_size\n",
    "            y_center = (box[1] + box[3]) / 2 / image_size\n",
    "            width = (box[2] - box[0]) / image_size\n",
    "            height = (box[3] - box[1]) / image_size\n",
    "            f.write(f\"0 {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "def process_images(model, images_folder, output_folder, device, confidence_threshold):\n",
    "    print(f\"Обработка изображений на устройстве: {device}\")\n",
    "    start_time = time.time()\n",
    "    processed_count = 0\n",
    "    total_detections = 0\n",
    "    boxes_list = []\n",
    "    for folder in os.listdir(images_folder):\n",
    "        folder_path = f\"{images_folder}/{folder}\"\n",
    "        if os.path.isdir(folder_path):\n",
    "            for image_path in os.listdir(folder_path):\n",
    "                full_image_path = f\"{folder_path}/{image_path}\"\n",
    "                predictions = model.predict(full_image_path, conf=confidence_threshold, device=device, verbose=False)\n",
    "                \n",
    "                if len(predictions[0].boxes.conf) > 0:\n",
    "                    boxes_data = {'source_image_path': full_image_path, 'coordinates': predictions[0].boxes.xyxy.tolist()}\n",
    "                    boxes_list.append(boxes_data)\n",
    "                    if not os.path.exists(f\"{output_folder}/{folder}\"):\n",
    "                        os.makedirs(f\"{output_folder}/{folder}\")\n",
    "                    final_image_path = f\"{output_folder}/{folder}/{image_path}\"\n",
    "                    copyfile(full_image_path, final_image_path)\n",
    "                    # predictions[0].save(final_image_path)\n",
    "                    create_annotation_file(full_image_path, predictions[0].boxes.xyxy.tolist(), f\"{output_folder}/{folder}\")                  \n",
    "                    processed_count += 1\n",
    "                    total_detections += len(predictions[0].boxes.conf)\n",
    "                    if processed_count % 10 == 0:  \n",
    "                        print(f\"Обработано: {processed_count} изображений с детекциями\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nГотово! Обработано {processed_count} изображений с детекциями\")\n",
    "    print(f\"Общее количество детекций: {total_detections}\")\n",
    "    print(f\"Время обработки: {end_time - start_time:.2f} секунд\")\n",
    "    print(f\"Устройство: {device}\")\n",
    "    return boxes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e10322e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA доступна: True\n",
      "Название GPU: NVIDIA GeForce RTX 5090\n",
      "Количество GPU: 2\n",
      "Текущий GPU device: 0\n",
      "Доступные устройства: ['cuda:0', 'cuda:1']\n",
      "Модель загружена на: cuda:0\n",
      "Модель загружена на: cuda:1\n"
     ]
    }
   ],
   "source": [
    "devices = get_devices()\n",
    "models = get_models(MODEL_NAME, devices)\n",
    "folder_name = get_destination_folder([PREDICT_FOLDER_PREFIX, MODEL_NAME, CONFIDENCE_THRESHOLD, \"3\"])\n",
    "output_folder = create_destination_folder(folder_name)\n",
    "total_detections, boxes_list = process_folder(f\"{SLICES_FOLDER}/2025_08_05_PhotoRieboR4_g201b201078_f003_289\", models[1], devices[1], output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e312bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source_image_path': 'slices/2025_08_05_PhotoRieboR4_g201b201078_f003_289/2025_08_05_PhotoRieboR4_g201b201078_f003_289_slice_005_002_1024_2560.png',\n",
       "  'coordinates': [[507.2154541015625,\n",
       "    627.23193359375,\n",
       "    522.3900146484375,\n",
       "    639.89697265625]]},\n",
       " {'source_image_path': 'slices/2025_08_05_PhotoRieboR4_g201b201078_f003_289/2025_08_05_PhotoRieboR4_g201b201078_f003_289_slice_005_014_7168_2560.png',\n",
       "  'coordinates': [[508.497802734375,\n",
       "    303.79150390625,\n",
       "    529.5006103515625,\n",
       "    328.8406982421875]]},\n",
       " {'source_image_path': 'slices/2025_08_05_PhotoRieboR4_g201b201078_f003_289/2025_08_05_PhotoRieboR4_g201b201078_f003_289_slice_005_015_7552_2560.png',\n",
       "  'coordinates': [[124.49765014648438,\n",
       "    303.7919921875,\n",
       "    145.500732421875,\n",
       "    328.84149169921875]]},\n",
       " {'source_image_path': 'slices/2025_08_05_PhotoRieboR4_g201b201078_f003_289/2025_08_05_PhotoRieboR4_g201b201078_f003_289_slice_006_001_512_3072.png',\n",
       "  'coordinates': [[614.8705444335938,\n",
       "    365.16461181640625,\n",
       "    630.8717651367188,\n",
       "    391.3114013671875]]},\n",
       " {'source_image_path': 'slices/2025_08_05_PhotoRieboR4_g201b201078_f003_289/2025_08_05_PhotoRieboR4_g201b201078_f003_289_slice_006_002_1024_3072.png',\n",
       "  'coordinates': [[102.8883056640625,\n",
       "    365.0743103027344,\n",
       "    119.10348510742188,\n",
       "    391.1580505371094]]},\n",
       " {'source_image_path': 'slices/2025_08_05_PhotoRieboR4_g201b201078_f003_289/2025_08_05_PhotoRieboR4_g201b201078_f003_289_slice_006_015_7552_3072.png',\n",
       "  'coordinates': [[358.95135498046875,\n",
       "    574.9954833984375,\n",
       "    386.58905029296875,\n",
       "    606.6878662109375],\n",
       "   [273.66522216796875,\n",
       "    420.4254455566406,\n",
       "    294.32244873046875,\n",
       "    460.9677429199219],\n",
       "   [550.8900146484375, 447.4313049316406, 575.14453125, 468.0815124511719]]},\n",
       " {'source_image_path': 'slices/2025_08_05_PhotoRieboR4_g201b201078_f003_289/2025_08_05_PhotoRieboR4_g201b201078_f003_289_slice_007_015_7552_3584.png',\n",
       "  'coordinates': [[358.98345947265625,\n",
       "    62.98992156982422,\n",
       "    386.57879638671875,\n",
       "    94.5417709350586]]},\n",
       " {'source_image_path': 'slices/2025_08_05_PhotoRieboR4_g201b201078_f003_289/2025_08_05_PhotoRieboR4_g201b201078_f003_289_slice_008_015_7552_4096.png',\n",
       "  'coordinates': [[581.5338745117188,\n",
       "    334.44232177734375,\n",
       "    601.1770629882812,\n",
       "    370.49188232421875],\n",
       "   [571.8455200195312,\n",
       "    497.9840087890625,\n",
       "    595.6000366210938,\n",
       "    518.290771484375]]},\n",
       " {'source_image_path': 'slices/2025_08_05_PhotoRieboR4_g201b201078_f003_289/2025_08_05_PhotoRieboR4_g201b201078_f003_289_slice_009_015_7552_4608.png',\n",
       "  'coordinates': [[570.71728515625,\n",
       "    0.0,\n",
       "    594.049560546875,\n",
       "    7.374460220336914]]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea093556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predicted_images_with_annotations-best_4-0.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from src.tools.utils import get_destination_folder\n",
    "if 'src.tools.utils' in sys.modules:\n",
    "    del sys.modules['src.tools.utils']\n",
    "predictions_destination_folder = get_destination_folder([PREDICT_FOLDER_PREFIX, MODEL_NAME, CONFIDENCE_THRESHOLD])\n",
    "predictions_destination_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f63ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir(predictions_destination_folder)\n",
    "outliers_destination_folder = get_destination_folder([PREDICT_FOLDER_PREFIX, MODEL_NAME, CONFIDENCE_THRESHOLD, OUTLIER_THRESHOLD_K])\n",
    "for folder in folders:\n",
    "    copyfolder(f\"{predictions_destination_folder}/{folder}\", f\"{outliers_destination_folder}/{folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17bd27e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'boxes_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mboxes_list\u001b[49m\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'boxes_list' is not defined"
     ]
    }
   ],
   "source": [
    "boxes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc17d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"boxes_list\", len(boxes_list))\n",
    "for boxes in boxes_list:\n",
    "    x_min = int(boxes['source_image_path'].split('/')[-1].split('_')[-2].split('.')[0])\n",
    "    y_min = int(boxes['source_image_path'].split('/')[-1].split('_')[-1].split('.')[0])\n",
    "\n",
    "    for box in boxes['coordinates']:\n",
    "        box[0] = box[0] + x_min\n",
    "        box[1] = box[1] + y_min\n",
    "        box[2] = box[2] + x_min\n",
    "        box[3] = box[3] + y_min\n",
    "\n",
    "boxes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dee9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорты уже выполнены в предыдущей ячейке\n",
    "def calculate_iou(box1, box2):\n",
    "    # box = [x1, y1, x2, y2]\n",
    "    x_left = max(box1[0], box2[0])\n",
    "    y_top = max(box1[1], box2[1])\n",
    "    x_right = min(box1[2], box2[2])\n",
    "    y_bottom = min(box1[3], box2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    print(\"intersection_area\", intersection_area)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "    print(\"union_area\", union_area)\n",
    "\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return intersection_area / union_area\n",
    "\n",
    "\n",
    "all_boxes = []\n",
    "for box_group in boxes_list:\n",
    "    source_path = box_group['source_image_path']\n",
    "    for coord in box_group['coordinates']:\n",
    "        all_boxes.append({\n",
    "            'coordinates': coord,\n",
    "            'source': source_path\n",
    "        })\n",
    "\n",
    "with_duplicates = len(all_boxes)\n",
    "print(f\"Всего боксов для сравнения: {with_duplicates}\")\n",
    "count = 0\n",
    "for i in range(len(all_boxes)):\n",
    "    for j in range(i + 1, len(all_boxes)):\n",
    "        iou = calculate_iou(all_boxes[i]['coordinates'], all_boxes[j]['coordinates'])\n",
    "        # print(\"iou\", iou)\n",
    "        if iou > IOU_THRESHOLD:\n",
    "            print(f\"Боксы с IoU > {IOU_THRESHOLD}:\")\n",
    "            print(f\"Бокс 1: {all_boxes[i]['coordinates']} (из {all_boxes[i]['source']})\")\n",
    "            print(f\"Бокс 2: {all_boxes[j]['coordinates']} (из {all_boxes[j]['source']})\")         \n",
    "            print(f\"IoU: {iou:.4f}\")\n",
    "            print(\"---\")\n",
    "            count += 1\n",
    "\n",
    "print(f\"Количество боксов с IoU > {IOU_THRESHOLD}: {count}\")\n",
    "without_duplicates = len(all_boxes) - count\n",
    "print(f\"Количество боксов без дубликатов: {without_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fefcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's count outliers for each image\n",
    "import numpy as np\n",
    "print(\"boxes_list\", len(boxes_list))\n",
    "\n",
    "filtered_boxes_from_outliers = []\n",
    "for boxes in boxes_list:\n",
    "    areas = []\n",
    "    for box in boxes['coordinates']:\n",
    "        box_area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "        areas.append(box_area)\n",
    "    mean_of_areas = sum(areas) / len(areas)\n",
    "\n",
    "    q1 = np.percentile(areas, 25)\n",
    "    q3 = np.percentile(areas, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - OUTLIER_THRESHOLD_K * iqr\n",
    "    upper_bound = q3 + OUTLIER_THRESHOLD_K * iqr\n",
    "    filtered_coordinates_from_outliers = []\n",
    "    for box in boxes['coordinates']:\n",
    "        box_area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "        if box_area > lower_bound and box_area < upper_bound:\n",
    "            filtered_coordinates_from_outliers.append(box)\n",
    "    \n",
    "    print(\"sum of areas\", sum(areas))\n",
    "    print(\"mean of areas\", mean_of_areas)\n",
    "    print(\"lower_bound\", lower_bound)\n",
    "    print(\"upper_bound\", upper_bound)\n",
    "    print(\"iqr\", iqr)\n",
    "    print(\"amount of filtered_coordinates_from_outliers\", len(filtered_coordinates_from_outliers))\n",
    "    if len(filtered_coordinates_from_outliers) > 0:\n",
    "        filtered_boxes_from_outliers.append({'source_image_path': boxes['source_image_path'], 'coordinates': filtered_coordinates_from_outliers})\n",
    "\n",
    "print(\"amount of filtered_boxes_from_outliers\", len(filtered_boxes_from_outliers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37622481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc10c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saiga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
